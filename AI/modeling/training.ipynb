{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "ddcec88e020af779e10f40e45778a5161119624e0ef81a5eabc1720c12dd07fe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (21.0.1)ERROR: Could not install packages due to an OSError: [WinError 5] 액세스가 거부되었습니다: 'C:\\\\Users\\\\김수현\\\\AppData\\\\Local\\\\Temp\\\\pip-uninstall-7zbwrfgl\\\\pip.exe'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "Collecting pip\n",
      "  Using cached pip-21.1.2-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.0.1\n",
      "    Uninstalling pip-21.0.1:\n",
      "      Successfully uninstalled pip-21.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torchvision==0.8.2 (from versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.9.0, 0.9.1, 0.10.0)\nERROR: No matching distribution found for torchvision==0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.8.2 torchaudio==0.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "urn self._get_build_requires(\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 127, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 248, in run_setup\n",
      "      super(_BuildMetaLegacyBackend,\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 142, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 2, in <module>\n",
      "      from setuptools_rust import Binding, RustExtension\n",
      "  ModuleNotFoundError: No module named 'setuptools_rust'\n",
      "  ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/1a/10/881a8c4b78499412c8a00b93457b484cf877e40f78c30f554fbd7e613fdd/tokenizers-0.8.0rc4.tar.gz#sha256=133a61fd6f5d1623fd21b7be857ca9a56ba18bd98c157895b3c1b3ac9df0df28 (from https://pypi.org/simple/tokenizers/). Command errored out with exit status 1: 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\python.exe' 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\김수현\\AppData\\Local\\Temp\\tmpcz9vqg5z' Check the logs for full command output.\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\python.exe' 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\김수현\\AppData\\Local\\Temp\\tmpzu_61__x'\n",
      "       cwd: C:\\Users\\김수현\\AppData\\Local\\Temp\\pip-install-1v849y4w\\tokenizers_d71982b6bba74a829cfb329d010af4bc\n",
      "  Complete output (20 lines):\n",
      "  Error in sitecustomize; set PYTHONVERBOSE for traceback:\n",
      "  SyntaxError: (unicode error) 'utf-8' codec can't decode byte 0xb1 in position 0: invalid start byte (sitecustomize.py, line 7)\n",
      "  Traceback (most recent call last):\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 280, in <module>\n",
      "      main()\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 263, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 114, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 146, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 127, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 248, in run_setup\n",
      "      super(_BuildMetaLegacyBackend,\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 142, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 2, in <module>\n",
      "      from setuptools_rust import Binding, RustExtension\n",
      "  ModuleNotFoundError: No module named 'setuptools_rust'\n",
      "  ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/83/9e/7163dc8ea080e901d8b6c0c64eb3c0b3ffe27a820145448b64d24ca78b97/tokenizers-0.7.0.tar.gz#sha256=a3cb9be31e3be381ab3f9e9ea7f96d4ba83588c40c44fe63b535b7341cdf74fe (from https://pypi.org/simple/tokenizers/). Command errored out with exit status 1: 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\python.exe' 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\김수현\\AppData\\Local\\Temp\\tmpzu_61__x' Check the logs for full command output.\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\python.exe' 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\김수현\\AppData\\Local\\Temp\\tmpljlenyb0'\n",
      "       cwd: C:\\Users\\김수현\\AppData\\Local\\Temp\\pip-install-1v849y4w\\tokenizers_ff1a6d683f8245cdbdd7f7f767743b61\n",
      "  Complete output (20 lines):\n",
      "  Error in sitecustomize; set PYTHONVERBOSE for traceback:\n",
      "  SyntaxError: (unicode error) 'utf-8' codec can't decode byte 0xb1 in position 0: invalid start byte (sitecustomize.py, line 7)\n",
      "  Traceback (most recent call last):\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 280, in <module>\n",
      "      main()\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 263, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 114, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 146, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 127, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 248, in run_setup\n",
      "      super(_BuildMetaLegacyBackend,\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 142, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 2, in <module>\n",
      "      from setuptools_rust import Binding, RustExtension\n",
      "  ModuleNotFoundError: No module named 'setuptools_rust'\n",
      "  ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/f5/d7/a3882b2d36991f613b749fc5e305cccc345ec9d6ab0621ad7e7bf1be8691/tokenizers-0.5.2.tar.gz#sha256=b5a235f9c71d04d4925df6c4fa13b13f1d03f9b7ac302b89f8120790c4f742bc (from https://pypi.org/simple/tokenizers/). Command errored out with exit status 1: 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\python.exe' 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\김수현\\AppData\\Local\\Temp\\tmpljlenyb0' Check the logs for full command output.\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\python.exe' 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\김수현\\AppData\\Local\\Temp\\tmphv973ask'\n",
      "       cwd: C:\\Users\\김수현\\AppData\\Local\\Temp\\pip-install-1v849y4w\\tokenizers_84d8a5b3e1cc4285a3069d3d190ace80\n",
      "  Complete output (20 lines):\n",
      "  Error in sitecustomize; set PYTHONVERBOSE for traceback:\n",
      "  SyntaxError: (unicode error) 'utf-8' codec can't decode byte 0xb1 in position 0: invalid start byte (sitecustomize.py, line 7)\n",
      "  Traceback (most recent call last):\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 280, in <module>\n",
      "      main()\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 263, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 114, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 146, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 127, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 248, in run_setup\n",
      "      super(_BuildMetaLegacyBackend,\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 142, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 2, in <module>\n",
      "      from setuptools_rust import Binding, RustExtension\n",
      "  ModuleNotFoundError: No module named 'setuptools_rust'\n",
      "  ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/4b/8e/bba2f969451a0f1989e57527bf2745e5455484c73905f3dfbab2f062ad92/tokenizers-0.5.0.tar.gz#sha256=24f60da7f382543cd0839437d231cb462e65fbc1461fc3622db55f6df34959d0 (from https://pypi.org/simple/tokenizers/). Command errored out with exit status 1: 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\python.exe' 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\김수현\\AppData\\Local\\Temp\\tmphv973ask' Check the logs for full command output.\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\python.exe' 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\김수현\\AppData\\Local\\Temp\\tmp0c75p1fr'\n",
      "       cwd: C:\\Users\\김수현\\AppData\\Local\\Temp\\pip-install-1v849y4w\\tokenizers_1b40b69ff5c34d7283be310e6577e690\n",
      "  Complete output (20 lines):\n",
      "  Error in sitecustomize; set PYTHONVERBOSE for traceback:\n",
      "  SyntaxError: (unicode error) 'utf-8' codec can't decode byte 0xb1 in position 0: invalid start byte (sitecustomize.py, line 7)\n",
      "  Traceback (most recent call last):\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 280, in <module>\n",
      "      main()\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 263, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 114, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 146, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 127, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 248, in run_setup\n",
      "      super(_BuildMetaLegacyBackend,\n",
      "    File \"c:\\users\\源\\x80\\xec닔\\xed쁽\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\build_meta.py\", line 142, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 2, in <module>\n",
      "      from setuptools_rust import Binding, RustExtension\n",
      "  ModuleNotFoundError: No module named 'setuptools_rust'\n",
      "  ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/6c/51/0eb780144128a7e7e108b507077b3a8099c908a8f5c1942db07cd8c312d1/tokenizers-0.0.11.tar.gz#sha256=4b7c42b644a1c5705a59b14c53c84b50b8f0b9c0f5f952a8a91a350403e7615f (from https://pypi.org/simple/tokenizers/). Command errored out with exit status 1: 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\python.exe' 'c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\김수현\\AppData\\Local\\Temp\\tmp0c75p1fr' Check the logs for full command output.\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\http\\client.py\", line 455, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\http\\client.py\", line 499, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 180, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 204, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 318, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 127, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 473, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 367, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 211, in _attempt_to_pin_criterion\n",
      "    for candidate in criterion.candidates:\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 129, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 33, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 200, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 306, in __init__\n",
      "    super().__init__(\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 151, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 234, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 317, in _prepare_distribution\n",
      "    return self._factory.preparer.prepare_linked_requirement(\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 508, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 550, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 239, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 102, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 157, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 152, in iter\n",
      "    for x in it:\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 62, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\contextlib.py\", line 135, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"c:\\users\\김수현\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n",
      "Processing c:\\users\\김수현\\desktop\\project\\honeylyrics\\server\\ai\\modeling\\kobert\n",
      "Building wheels for collected packages: kobert\n",
      "  Building wheel for kobert (setup.py): started\n",
      "  Building wheel for kobert (setup.py): finished with status 'done'\n",
      "  Created wheel for kobert: filename=kobert-0.1.2-py3-none-any.whl size=12769 sha256=27954bb29d03b1fa41e1b034bca79cf0bc7bc5796dd864d644cca318c44b2eb8\n",
      "  Stored in directory: C:\\Users\\김수현\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-1gzbiuuh\\wheels\\ab\\ee\\4c\\46f678c5692f0e872c63aa66595abd086d5eea77ce392c4fb0\n",
      "Successfully built kobert\n",
      "Installing collected packages: kobert\n",
      "Successfully installed kobert-0.1.2\n",
      "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/SKTBrain/KoBERT.git\n",
    "%cd KoBERT/\n",
    "!pip install -r requirements.txt\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.9.0+cpu'"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from kobert.utils import get_tokenizer \n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model \n",
    "\n",
    "from transformers import AdamW \n",
    "from transformers.optimization import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#koBERT의 토크나이저를 사용합니다\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "        print(self.labels, label_idx)\n",
    "        self.labels.sort()\n",
    "        print(self.labels)\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   그 날을 잊지 못해 날 보며 환히 웃던 너의 미소에 홀린 듯 너무 쪽팔림에 난 그저 한마디 말도 못해 너의 눈빛은 날 자꾸 네 곁을 맴돌게 해 굳게 닫힌 내 맘이 어느새 무너져버려 온통 너의 생각뿐이야 나도 미치겠어 너무 보고 싶어 매일 매일 매일 자꾸 초라해지잖아 내 모습이 그대여 내게 말해줘 사랑한다고 하루가 멀다 하고 기다리고 있잖아 기다리고 있잖아 오늘 밤이 가기 전에 조금 더 다가와 줘 대체 뭘 고민해 빨리 안아 아닌 척 모르는 척 하다가 늦게 놓치고 후회 말아 너의 눈빛은 날 자꾸 네 곁을 맴돌게 해 굳게 닫힌 내 맘이 어느새 무너져버려 온통 너의 생각뿐이야 나도 미치겠어 너무 보고 싶어 매일 매일 매일 자꾸 초라해지잖아 내 모습이 그대여 내게 말해줘 사랑한다고 하루가 멀다 하고 기다리고 있잖아 이제 와 숨기려 하지 마요 그대여 아닌 척하지 마요 온종일 난 그대 생각에 잠긴 채로 난 이대로 기다리고 있어요 하루가 멀다 하고 기다리고 있잖아 기다리고 있잖아  \\\n",
       "0   나리는 꽃가루에 눈이 따끔해 아야 눈물이 고여도 꾹 참을래 내 마 한켠 비밀스런 오...                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "1   넌 운전만 해 계속 운전만 해 왜 이리 된 걸까 우리 사이가 갑자기 어색해졌단 걸 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "2   세상의 모서리 구부정하게 커버린 골칫거리 걸음걸이 옷차림 이어폰 너머 악까지 다 넌...                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "3   어쩜 살아가다 보면 한 번은 날 찾을지 몰라 나 그 기대 하나로 오늘도 힘겹게 버틴...                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "4   그대는 참 아름다워요 밤 하늘의 별빛보다 빛나요 지친 나의 마음을 따뜻하게 감싸줄 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "..                                                ...                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "85  희망을 걸어 모두가 날더러 더 힘들 거라고 얘기했어 그래서 뭐 난 너를 믿어 추운 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "86  그 날을 잊지 못해 날 보며 환히 웃던 너의 미소에 홀린 듯 너무 쪽팔림에 난 그저...                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "87  나리는 꽃가루에 눈이 따끔해 아야 눈물이 고여도 꾹 참을래 내 마 한켠 비밀스런 오...                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "88  넌 운전만 해 계속 운전만 해 왜 이리 된 걸까 우리 사이가 갑자기 어색해졌단 걸 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "89  세상의 모서리 구부정하게 커버린 골칫거리 걸음걸이 옷차림 이어폰 너머 악까지 다 넌...                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "\n",
       "     2  \n",
       "0    0  \n",
       "1    5  \n",
       "2    1  \n",
       "3   15  \n",
       "4   21  \n",
       "..  ..  \n",
       "85   1  \n",
       "86   7  \n",
       "87   1  \n",
       "88  11  \n",
       "89  11  \n",
       "\n",
       "[90 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>그 날을 잊지 못해 날 보며 환히 웃던 너의 미소에 홀린 듯 너무 쪽팔림에 난 그저 한마디 말도 못해 너의 눈빛은 날 자꾸 네 곁을 맴돌게 해 굳게 닫힌 내 맘이 어느새 무너져버려 온통 너의 생각뿐이야 나도 미치겠어 너무 보고 싶어 매일 매일 매일 자꾸 초라해지잖아 내 모습이 그대여 내게 말해줘 사랑한다고 하루가 멀다 하고 기다리고 있잖아 기다리고 있잖아 오늘 밤이 가기 전에 조금 더 다가와 줘 대체 뭘 고민해 빨리 안아 아닌 척 모르는 척 하다가 늦게 놓치고 후회 말아 너의 눈빛은 날 자꾸 네 곁을 맴돌게 해 굳게 닫힌 내 맘이 어느새 무너져버려 온통 너의 생각뿐이야 나도 미치겠어 너무 보고 싶어 매일 매일 매일 자꾸 초라해지잖아 내 모습이 그대여 내게 말해줘 사랑한다고 하루가 멀다 하고 기다리고 있잖아 이제 와 숨기려 하지 마요 그대여 아닌 척하지 마요 온종일 난 그대 생각에 잠긴 채로 난 이대로 기다리고 있어요 하루가 멀다 하고 기다리고 있잖아 기다리고 있잖아</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>나리는 꽃가루에 눈이 따끔해 아야 눈물이 고여도 꾹 참을래 내 마 한켠 비밀스런 오...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>넌 운전만 해 계속 운전만 해 왜 이리 된 걸까 우리 사이가 갑자기 어색해졌단 걸 ...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>세상의 모서리 구부정하게 커버린 골칫거리 걸음걸이 옷차림 이어폰 너머 악까지 다 넌...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>어쩜 살아가다 보면 한 번은 날 찾을지 몰라 나 그 기대 하나로 오늘도 힘겹게 버틴...</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>그대는 참 아름다워요 밤 하늘의 별빛보다 빛나요 지친 나의 마음을 따뜻하게 감싸줄 ...</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>희망을 걸어 모두가 날더러 더 힘들 거라고 얘기했어 그래서 뭐 난 너를 믿어 추운 ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>그 날을 잊지 못해 날 보며 환히 웃던 너의 미소에 홀린 듯 너무 쪽팔림에 난 그저...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>나리는 꽃가루에 눈이 따끔해 아야 눈물이 고여도 꾹 참을래 내 마 한켠 비밀스런 오...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>넌 운전만 해 계속 운전만 해 왜 이리 된 걸까 우리 사이가 갑자기 어색해졌단 걸 ...</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>세상의 모서리 구부정하게 커버린 골칫거리 걸음걸이 옷차림 이어폰 너머 악까지 다 넌...</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n<p>90 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=25,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 20\n",
    "max_grad_norm = 1 \n",
    "log_interval = 200 \n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/content/sample_data/result.csv', names=['lyrics', 'mood'])\n",
    "df.to_csv('/content/sample_data/result_nonheader.csv', index=False, header=False)\n",
    "df = pd.read_csv('/content/sample_data/result_nonheader.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[df.iloc[i][0], df.iloc[i][1]] for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Global seed set to 42\n",
      "Using PyTorch Ver 1.9.0+cpu\n",
      "Fix Seed: 42\n",
      "Downloading: 100%|██████████| 672/672 [00:00<00:00, 343kB/s]\n",
      "Downloading: 100%|██████████| 1.34G/1.34G [04:48<00:00, 4.66MB/s]\n",
      "Some weights of the model checkpoint at beomi/kcbert-large were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|██████████| 250k/250k [00:00<00:00, 357kB/s]\n",
      "Downloading: 100%|██████████| 49.0/49.0 [00:00<00:00, 50.7kB/s]\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      ":: Start Training ::\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "MisconfigurationException",
     "evalue": "You have asked for native AMP on CPU, but AMP is only available on GPU.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-90c1eee0aebe>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":: Start Training ::\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     trainer = Trainer(\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mfast_dev_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\env_vars_connector.py\u001b[0m in \u001b[0;36minsert_env_defaults\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# all args were already moved to kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minsert_env_defaults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logger, checkpoint_callback, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, gpus, auto_select_gpus, tpu_cores, log_gpu_memory, progress_bar_refresh_rate, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, sync_batchnorm, precision, weights_summary, weights_save_path, num_sanity_val_steps, truncated_bptt_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_epoch, auto_lr_find, replace_sampler_ddp, terminate_on_nan, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, distributed_backend, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_connector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptimizerConnector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         self.accelerator_connector = AcceleratorConnector(\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[0mnum_processes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpu_cores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistributed_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_select_gpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msync_batchnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mreplace_sampler_ddp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamp_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamp_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugins\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_processes, tpu_cores, distributed_backend, auto_select_gpus, gpus, num_nodes, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, precision, amp_type, amp_level, plugins)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_given_plugins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_accelerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;31m# override dist backend when using tpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py\u001b[0m in \u001b[0;36mselect_accelerator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         return acc_cls(\n\u001b[1;32m--> 483\u001b[1;33m             \u001b[0mprecision_plugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m             \u001b[0mtraining_type_plugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py\u001b[0m in \u001b[0;36mprecision_plugin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprecision_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mPrecisionPlugin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_precision_plugin\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_precision_plugin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_precision_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_precision_plugin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py\u001b[0m in \u001b[0;36mselect_precision_plugin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamp_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mAMPType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNATIVE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_cpu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m                     raise MisconfigurationException(\n\u001b[0m\u001b[0;32m    351\u001b[0m                         \u001b[1;34m\"You have asked for native AMP on CPU, but AMP is only available on GPU.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                     )\n",
      "\u001b[1;31mMisconfigurationException\u001b[0m: You have asked for native AMP on CPU, but AMP is only available on GPU."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation, test set을 나눠주세요\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset_train, dataset_test = train_test_split(data, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 만들고 GPU 사용 설정을 해줍니다\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#옵티마이저와 손실함수 설정\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, warmup_step, t_total)\n",
    "\n",
    "#정확도를 계산하기 위한 함수\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 과정\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad() \n",
    "        token_ids = token_ids.long().to(device) \n",
    "        segment_ids = segment_ids.long().to(device) \n",
    "        valid_length= valid_length \n",
    "        label = label.long().to(device) \n",
    "        out = model(token_ids, valid_length, segment_ids) \n",
    "        loss = loss_fn(out, label) \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) \n",
    "        optimizer.step() \n",
    "        scheduler.step()  # Update learning rate schedule \n",
    "        train_acc += calc_accuracy(out, label)  \n",
    "        if batch_id % log_interval == 0: \n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1))) \n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1))) \n",
    "    model.eval() #모델 평가 부분 \n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# 평가용 Test_set을 모델에 입력하기 위해 형식을 맞춰줍니다\n",
    "\n",
    "sentence_eval[\"emotion\"] = sentence_eval[\"emotion\"].apply(label)\n",
    "\n",
    "dtls_eval = [list(sentence_eval.iloc[i,:]) for i in range(len(sentence_eval))]\n",
    "\n",
    "data_test = BERTDataset(dtls_eval, 0, 1, tok, max_len, True, False)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 데이터에 대해 분류를 시작합니다\n",
    "model.eval()\n",
    "answer=[]\n",
    "train_acc = 0.0\n",
    "test_acc = 0.0\n",
    "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "  token_ids = token_ids.long().to(device)\n",
    "  segment_ids = segment_ids.long().to(device)\n",
    "  valid_length= valid_length\n",
    "  label = label.long().to(device)\n",
    "  out = model(token_ids, valid_length, segment_ids)\n",
    "  max_vals, max_indices = torch.max(out, 1)\n",
    "  answer.append(max_indices.cpu().clone().numpy())\n",
    "  test_acc += calc_accuracy(out, label)\n",
    "print('정답률: ',test_acc / (batch_id+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 형식에 맞춰 파일을 저장해줍니다\n",
    "ls = []\n",
    "for i in answer:\n",
    "  ls.extend(i)\n",
    "\n",
    "pred = pd.DataFrame(ls, columns=['Predicted'])\n",
    "df = pd.concat([sentence_eval['raw_text'], pred['Predicted'], sentence_eval['emotion']], axis=1) \n",
    "\n",
    "def test(x):\n",
    "  if x==0.0: return '슬픔'\n",
    "  elif x==1.0: return '기쁨'\n",
    "  elif x==2.0: return '분노'\n",
    "  elif x==3.0: return '공포'\n",
    "  else: return x\n",
    "\n",
    "df[\"Predicted\"] = df[\"Predicted\"].apply(test)\n",
    "df[\"emotion\"] = df[\"emotion\"].apply(test)\n",
    "\n",
    "for i in ['슬픔','기쁨','분노','공포']: \n",
    "  print(i, '개수', len(df[df['emotion'] == i]))\n",
    "  print('예측 개수', len(df[df['emotion'] == i][df['Predicted'] == i]))\n",
    "  print('정답률',len(df[df['emotion'] == i][df['Predicted'] == i])/len(df[df['emotion'] == i]))"
   ]
  }
 ]
}